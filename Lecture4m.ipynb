{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1aBoG9pMebCbCCxnIrkLLoodmWsyybnDE","timestamp":1674517127105}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Reading: Chapter 4. Chapter 16 pages 290 - 292.\n","\n","Lecture Topics:\n","\n","1. Statistics\n","2. Correlation\n","3. K-means Clustering Alorithm"],"metadata":{"id":"AqhVMYyDC16H"}},{"cell_type":"markdown","source":["### I. Statistics Definitions\n","\n","\n","\n","*   A <u>population</u> is a complete collection of all subjects we wish to study.\n","*   A *sample* is a subset of the population.\n","*   A *variable* is a characteristic of each population member that we wish to study. In data science and machine learning a variable is often called a *feature*.\n","*   *Data* are measurements of a variable or variables.\n","\n","\n","\n","a) The *mean* of a vector $x$ is defined as $\\bar{x} = \\frac{\\Sigma_{i = 1}^nx_i}{n}$. It is a measure of center for the data vector $x$.\n","\n","b) The *standard deviation* of a vector $x$ is defined as $s_x = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n}}$. It is a measure of spread for the data vector $x$.  \n","\n","c) A variable that is rescaled via the equation $z_i = (x_i - \\bar{x})/s_x$ is  *standardized*. $z_i$ gives the number of standard deviations that $x_i$ is above (or below) the mean.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"yFV-ZMTQD4-z"}},{"cell_type":"markdown","source":["**Example**: Compute the sample mean and sample standard deviation for ```x = np.array([-1, 2, 9, 20, 2, -3, -4, 9, 10, 0])\n","```. Find the number of standard deviations ```x[0]``` is from the mean."],"metadata":{"id":"d7l9s5vdcYJV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WexMu1LDC04r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674765023810,"user_tz":480,"elapsed":247,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"c4efa1f4-497d-43ec-e50c-4086a01cb89b"},"outputs":[{"output_type":"stream","name":"stdout","text":["10\n","4.4\n","4.4\n","7.08801805866774\n","-0.7618490747771856\n"]}],"source":["import numpy as np\n","import math\n","\n","x = np.array([-1, 2, 9, 20, 2, -3, -4, 9, 10, 0])\n","\n","x_bar = sum(x)/x.shape[0] #len\n","\n","print(x.shape[0])\n","print(x_bar)\n","\n","x_bar = np.mean(x);\n","\n","print(x_bar)\n","\n","#standard deviation\n","\n","#x_x = sum[(x - x_bar)]**2\n","#len = x.shape\n","#s_x = math.sqrt(x_x / len)\n","\n","s_x = np.std(x)\n","\n","print(s_x)\n","\n","\n","#z\n","z_0 = (x[0]-x_bar) / s_x\n","print(z_0)"]},{"cell_type":"code","source":["import numpy as np\n","import math\n","\n","x = np.array([3.0,4,2,3,5,3,4,1,2,1])\n","y = np.array([1.0,3,5,5,2,2,6,5,4,2])\n","print(x)\n","print(y)\n","x_bar = np.mean(x);\n","print(x_bar)\n","y_bar = np.mean(y);\n","x_x = sum[(x - x_bar)]**2\n","y_y = sum[(y - y_bar)]**2\n","len_x = x.shape\n","len_y = y.shape\n","s_xy = math.sqrt((x_x / len_x) + (y_y / len_y))\n","print(s_xy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"id":"YBc7aGSQvRtr","executionInfo":{"status":"error","timestamp":1681760956434,"user_tz":420,"elapsed":168,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"6984ca5d-2989-4877-b6da-3e571f4b544b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3. 4. 2. 3. 5. 3. 4. 1. 2. 1.]\n","[1. 3. 5. 5. 2. 2. 6. 5. 4. 2.]\n","2.8\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-1e9d9ef8a34f>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlen_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"]}]},{"cell_type":"markdown","source":["**Example**: Standardize data vector x from the previous example using ```preprocessing``` package from the ```sklearn``` library."],"metadata":{"id":"DLCgZTfXc1gt"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","\n","x = np.array([[-1], [2], [9], [20], [2], [-3], [-4], [9], [10], [0]])\n","\n","scaler = preprocessing.StandardScaler() #construct the scalar object\n","standardized_x = scaler.fit_transform(x) #deploy and calculate\n","#standardized_x = scaler.fit_transform(x.reshape(-1,1))\n","print(standardized_x)"],"metadata":{"id":"SKugmOsgwEed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674519378383,"user_tz":480,"elapsed":6,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"9588516f-3f7f-452c-b26e-0d5bd29a4055"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.76184907]\n"," [-0.33859959]\n"," [ 0.64898255]\n"," [ 2.20089733]\n"," [-0.33859959]\n"," [-1.0440154 ]\n"," [-1.18509856]\n"," [ 0.64898255]\n"," [ 0.79006571]\n"," [-0.62076591]]\n"]}]},{"cell_type":"markdown","source":["**Exercise**: Write a python function ```standardize(v)``` that takes an arbitrary vector ```v``` and returns a standardized vector. (See Lab 2.)"],"metadata":{"id":"5Okty6pSdZKL"}},{"cell_type":"markdown","source":["### II. Correlation\n","\n","The Pearson Correlation Coefficient and Cosine Similarity are both measures of how closely two different data vectors correspond with each other (linear relationship).\n","\n","$r = \\frac{\\Sigma_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\Sigma_{i=1}^n(y_i-\\bar{y})^2}}$\n","\n","Define the *de-meaned* (centered) vectors $\\tilde{x} = x - \\bar{x}$ and $\\tilde{y} = x - \\bar{y}$. Then\n","\n","$r = \\frac{\\tilde{x}^T\\tilde{y}}{||\\tilde{x}|| ||\\tilde{y}||}$.\n","\n","**Questions**:\n","\n","1. What is the largest and smallest values that $r$ can take?\n","\n","2. Is it possible to have $r = 0$? What does this mean geometrically?"],"metadata":{"id":"ZZV9nckFDk8V"}},{"cell_type":"markdown","source":["**Exercise**: Find and interpret the correlation coeffient for the following vector pairs."],"metadata":{"id":"SLGvm-TselHh"}},{"cell_type":"code","source":["import numpy as np\n","\n","x1 = np.array([1, 2, 3])\n","y1 = np.array([2, 4, 7]) # What do you notice about these two vectors?\n","\n","col1 = np.correlate(x1, y1)\n","col1 = np.corrcoef(x1, y1)\n","print(col1)\n","#col2 = np.correlate(y1)\n","\n","x2 = np.array([-10, 2, 9, 20, 21, -3, -4, 9, 10, 0])\n","y2 = np.array([-2, -13, 8, 1, 0, 0, 12, 2, 10, 1]) # I randomly chose the numbers for these vectors\n","\n","col2 = np.corrcoef(x2, y2)\n","print(col2)\n"],"metadata":{"id":"DN71SN69ZPHD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674520300068,"user_tz":480,"elapsed":4,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"39f7cd8f-92a3-4f3f-a984-ae8a19d94ca6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.         0.99339927]\n"," [0.99339927 1.        ]]\n","[[1.         0.08200585]\n"," [0.08200585 1.        ]]\n"]}]},{"cell_type":"markdown","source":["### III. K-Means Clustering\n","\n","*Supervised Learning*: Algorithm is trained on labeled data, then its accuracy/effectiveness is tested by having the algorithm predict labels on other data and measuring how well it does. Example: email spam filter.\n","\n","*Unsupervised Learning*: Algorithm is run (trained) on unlabled data, no way to see if it did what it was \"supposed to do.\" Example: clustering vectors that are \"similar.\"\n","\n","In supervised learning we define an objective function that uses the labeled outcomes in our dataset to check for algorithm convergence. Since K-Means is an unsupervised method we need to be creative in coming up with the objective function ourselves. This can be done in many different ways. The most common is using Eculidian distance to measure whether or not a particular grouping is actually \"grouped.\"\n","\n","More formally, if $z_1, ..., z_k$ are the group centroid vectors with $j \\in {1, ... , k}$, and $c_i = j$, we define the objective function as\n","\n","$J^{clust} = (||x_1 - z_{c_1}||^2 + ||x_2 - z_{c_2}||^2 + ... + ||x_n - z_{c_n}||^2)/n.$\n","\n","We have found an \"optimal\" grouping when $J^{clust}$ is minimized. We can miminize $J^{clust}$ by minimizing each inidividual $||x_i - z_{c_i}||$. Thus, the optimal grouping solution is found by\n","\n","$\\begin{align} \\underset{j = 1, 2, ..., k}{min} ||x_1 - z_j|| + \\underset{j = 1, 2, ..., k}{min}||x_2 - z_j|| + ... + \\underset{j = 1, 2, ..., k}{min}||x_n - z_j||.\\end{align}$\n","\n","K-Means Clustering Algorithm:\n","\n","1. Choose *k*, the number of groups. Randomly initialize *k* centroids.\n","2. Compute the Euclidian distance between each data observation (vector) and each of the *k* centroids.\n","3. Assign each vector to the group with the closest centroid.\n","4. Update each centroid as the average of all vectors assigned to that centroid's group.\n","5. Repeat steps 2-4 until convergence.  "],"metadata":{"id":"lIQPUHE743R5"}},{"cell_type":"markdown","source":["**Example**: Group the following data vectors into two groups (by hand). Assume that z0 = x2 and z1 = x2 are randomly chose to be the initial group centroids. Assume that both variables were measured on the same scale (why is this important?).\n","\n","x0 = [1, 1],\n","x1 = [1, 0],\n","x2 = [0, 2],\n","x3 = [2, 4],\n","x4 = [3, 5].\n","\n"],"metadata":{"id":"pwcycGuH-G9-"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","X = np.array([[1, 1], [1,0], [0, 2], [2, 4], [3, 5]])\n","\n","\n","z_0 = np.array([1,0.5])\n","z_1 = np.array([1.7, 3.7])\n","\n","J_1 = (np.dot(X[0]-z_0, X[0]- z_0) +  np.dot(X[1]-z_0, X[1]- z_0) +  np.dot(X[2]-z_0, X[2]- z_0) +  np.dot(X[3]-z_1, X[3]- z_1) +  np.dot(X[4]-z_1, X[4]- z_1))/5\n","\n","z_0 = (X[0] + X[1] + X[2])/3\n","z_1 = (X[3] + X[4])/2\n","\n","J_2 = (np.dot(X[0]-z_0, X[0]- z_0) +  np.dot(X[1]-z_0, X[1]- z_0) +  np.dot(X[2]-z_0, X[2]- z_0) +  np.dot(X[3]-z_1, X[3]- z_1) +  np.dot(X[4]-z_1, X[4]- z_1))/5\n","print(J_2)\n"],"metadata":{"id":"y0537a9yDO2c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674773018461,"user_tz":480,"elapsed":653,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"40f22c13-2d01-489c-c08e-8b4aefb4a29c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7333333333333334\n"]}]},{"cell_type":"markdown","source":["**Example**: Use the ```cluster``` module from the ```sklearn``` library in python to group the vectors in the previous example."],"metadata":{"id":"VFejmZptJJW3"}},{"cell_type":"code","source":["from sklearn import cluster\n","\n","# Initialize the cluster object\n","kmeans_ex = cluster.KMeans(n_clusters=2, n_init = 10, random_state=2)"],"metadata":{"id":"m17vvisI4idf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the algorithm\n","label = kmeans_ex.fit_predict(X)"],"metadata":{"id":"vbSmGeMUk9L8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Get unique labels for plotting purposes\n","u_labels = np.unique(label)\n","\n","#plot\n","centers = np.array(kmeans_ex.cluster_centers_)\n","for i in u_labels:\n","    plt.scatter(X[label == i , 0] , X[label == i , 1] , label = i)\n","plt.scatter(centers[:,0], centers[:,1], marker=\"x\", color='k')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"QqH9ZbybqnUW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use results\n","kmeans_ex.labels_\n","kmeans_ex.cluster_centers_\n","kmeans_ex.predict([[0, 0], [12, 3]])"],"metadata":{"id":"pbNC6wAPFUsO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### IV. The Iris Dataset\n","\n","The \"Iris\" dataset is a classic in statistics (read about it at https://en.wikipedia.org/wiki/Iris_flower_data_set). Ronald Fisher (widely considered the father of modern statistics; he developed the majority of techniques that are fundamental to the discipline) introduced it to demonstrate the effectiveness of his Linear Discriminant Analysis (LDA) method. LDA is a fundamental classification (supervised machine learning) method: for the iris problem it uses the 4 numerical variables as inputs and then predicts which of iris species a flower belongs to based on those inputs. That is, it is a supervised learning technique since it makes predictions using labeled data (the dataset includes observed iris species for each flower). We will revisit this dataset in the second half of the class when we study classification methods.\n","\n","\n","\n","\n","\n","    \n","\n"],"metadata":{"id":"QX49h39LyN2d"}},{"cell_type":"code","source":["# Step 1: Initialize the import object to give colab access to our computer\n","\n","from google.colab import files\n","\n","uploaded = files.upload()"],"metadata":{"id":"wAIU-yVIoEAx","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1674511796914,"user_tz":480,"elapsed":8815,"user":{"displayName":"Andrew Jorgenson","userId":"01932931749841799462"}},"outputId":"0598d26d-7e1c-4cd0-d7ed-3826e46417e6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8332ed61-abec-4b06-be55-78949fc31141\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8332ed61-abec-4b06-be55-78949fc31141\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving iris.csv to iris.csv\n"]}]},{"cell_type":"code","source":["# Step 2: Import and view dataset\n","\n","import pandas as pd\n","\n","iris = pd.read_csv(\"iris.csv\")\n","iris.head()"],"metadata":{"id":"kXCJfbr8p6KY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Questions**:\n","\n","1. Does this dataset contain measurements on a population or a sample?\n","2. After importing the iris dataset  we can view the ```variety``` variable. Will the K-Means method utilize this part of the dataset? (Hint: We're about to group the examples in the dataset using K-Means, which is an _____ learning method.)"],"metadata":{"id":"fet_oeOMnylR"}},{"cell_type":"markdown","source":["**Example**: Use ```sklearn``` to group the data in the ```iris``` dataset."],"metadata":{"id":"U61r_rQ2Ipmm"}},{"cell_type":"code","source":["# Step 3: Preprocess the dataset by converting from pandas dataframe to a numpy ndarray and drop last column\n","X = iris.to_numpy()\n","print(X)"],"metadata":{"id":"-PNuS_LUIkJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 4: Preprocess the dataset by standardizing each variable\n","from sklearn import preprocessing\n","\n","scaler = preprocessing.StandardScaler()\n","X = scaler.fit_transform(X)"],"metadata":{"id":"VDX6o_-kIoUq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import cluster\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Step 5: Initialize K-Means cluster object\n","kmeans_iris = cluster.KMeans(n_clusters=3, n_init = 10, random_state=0)\n","\n","# Step 6: Use kmeans_iris's \"fit_predict()\" method to predict the groups for each value in the dataset\n","label = kmeans_iris.fit_predict(X)\n","\n","# Step 7: Get unique labels (group labels) using numpy's \"unique\" method\n","u_labels = np.unique(label)\n","\n","# Step 8: Plot the results:\n","centers = np.array(kmeans_iris.cluster_centers_)\n","for i in u_labels:\n","    plt.scatter(X[label == i , 0] , X[label == i , 1], label = i)\n","plt.scatter(centers[:,0], centers[:,1], marker=\"x\", color='k')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"qOFThwfY4eLZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Questions**:\n","\n","1. Why does the horizontal axis start at -2?\n","2. An *outlier* is a data value that falls far from the mean. There is not universally accepted definition for outlier but a commonly used rule-of-thumb is \"farther than 2 standard deviations from the mean.\" Do their appear to be any outliers in the iris dataset?\n","3. Why do the groups appear to overlap? What does this indicate about the way the K-Means algorithm grouped the irises?"],"metadata":{"id":"9a1QegOY4mQ9"}}]}
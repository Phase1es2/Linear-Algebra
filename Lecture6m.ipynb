{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xs4fZa-0xKJ2xQGlIHmLXLxehlT6oj53","timestamp":1675727616036}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Reading: Chapter 5 pages 72-76, Chapter 6 pages 81-88.\n"],"metadata":{"id":"5ajtDagyBfNm"}},{"cell_type":"markdown","source":["### I. Matrix Transpose\n","\n","a) $[a_{ij}]^T = [a_{ji}]$ (Compact definition of the $A^T$)\n","\n","b) $(LIVE)^T = E^TV^TI^TL^T$ (How the transpose relates to the matrix product)\n","\n","c) Symmetric Matrices: $A = A^T$ (A special case)"],"metadata":{"id":"nZrizDnRGCcW"}},{"cell_type":"code","source":["import numpy as np\n","\n","A = np.array([[2,2,3],[1,4,5],[9,3,2]])\n","B = np.array([[-1,-3,9],[2,-6,2],[9,8,7]])\n","C = np.array([[7,6],[8,-1],[9,2]])\n","D = np.array([[-2, 3, 1], [9, 2, 3]])\n","I3 = np.eye(len(A))\n","Ones = np.ones((3,3))\n","Zeros = np.zeros((3,3))\n","v = np.array([[1],[-2],[3]])\n","u = np.array([[1,-2,3]])\n","l = 2\n"],"metadata":{"id":"LYavG1J3IZi2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise**. Suppose $D_1$ is 3 x 4, $D_2$ is 4 x 7, $D_3$ is 2 x 7, and $\\vec{v} \\in \\mathbb{R}^2$. Is $D_1D_2D_3^T\\vec{v}$ defined? If so, what are its dimensions?  "],"metadata":{"id":"0K3Cz3IeLTJc"}},{"cell_type":"markdown","source":["**Exercise**. For any matrix $A$, what are the properties of $A^TA$? Illustrate these properties with examples in python."],"metadata":{"id":"RDHwnIpZKlTv"}},{"cell_type":"code","source":["import numpy as np\n","print(A.T)\n","\n","ata = A.T@A\n","\n","\n","print(ata)\n","print()\n","\n","print(ata.T)\n","#simatrical"],"metadata":{"id":"_-tCEtl5JSNW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675727716813,"user_tz":480,"elapsed":494,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"477a976d-91ab-44c9-bd28-654e13371f4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2 1 9]\n"," [2 4 3]\n"," [3 5 2]]\n","[[86 35 29]\n"," [35 29 32]\n"," [29 32 38]]\n","\n","[[86 35 29]\n"," [35 29 32]\n"," [29 32 38]]\n"]}]},{"cell_type":"code","source":["C = np.array([[7,6],[8,-1],[9,2]])\n","ctc = C@C.T\n","print(ctc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCqkD2WMKCUz","executionInfo":{"status":"ok","timestamp":1675727871163,"user_tz":480,"elapsed":142,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"e8d8ef95-04aa-4c85-e6f1-80789b8709b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[85 50 75]\n"," [50 65 70]\n"," [75 70 85]]\n"]}]},{"cell_type":"code","source":["3 X 4 * 4 X 7 =3 X 7\n","v = 2 by 1\n","3 by 1\n"],"metadata":{"id":"62eGOtYJI7iE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Transpose Application: Multivariate Data Covariance Matrices.\n","\n","Recall the Pearson Correlation Coefficient measures of how closely two different data vectors correspond with each other (linear relationship).\n","\n","$r = \\frac{\\Sigma_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\Sigma_{i=1}^n(y_i-\\bar{y})^2}} = \\frac{\\tilde{x}\\cdot\\tilde{y}}{||\\tilde{x}|| ||\\tilde{y}||}$.\n","\n","The <u>covariance</u> of two vectors $\\vec{x}$ and $\\vec{y}$ is defined as\n","\n","$c_{x,y} = \\frac{\\Sigma_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{n-1} = \\frac{\\tilde{x}\\cdot\\tilde{y}}{n-1}$.\n","\n","Note that $c_{x,y}$ is just a variation of $r$: it has the same numerator but is \"scaled\" by a different denominator."],"metadata":{"id":"AjhKTd4nfzLs"}},{"cell_type":"markdown","source":["**Exercise**. Suppose you have a (presumably tall) $n \\times m$ data matrix $X$. Write an expression for $C$, the data's $m \\times m$ covariance matrix. (Hint: see previous exercise.)"],"metadata":{"id":"_Y-dpHf9fUxN"}},{"cell_type":"code","source":[],"metadata":{"id":"FfJ4YhtkMzjE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### II. Matrix Norms\n","\n","Recall that the *Euclidian Norm* (2-Norm) of a vector $\\vec{v}$ is $||v|| = \\sqrt{\\sum_{i=1}^nv_i^2}$. This is a measure of vector magnitude.\n","\n","The *Frobenius Norm* ($\\ell2$ norm) of a matrix is defined as $||A||_F = \\sqrt{\\sum_{i=1}^N \\sum_{j=1}^Ma_{ij}^2}$.\n","\n","The *trace* of a matrix is the sum of its diagonal elements: $tr(A) = \\sum_{i=1}^N a_{ii}$.\n","\n","Interesting property: $||A||_F = \\sqrt{tr(A^TA)}$."],"metadata":{"id":"lNj3ZxEf7fcy"}},{"cell_type":"markdown","source":["**Exercise**. Calculate the Frobenius norm for matrix $A$ by using a double for-loop. Verify that your function works correctly using ```norm``` from the ```numpy.linalg``` library.   "],"metadata":{"id":"EtdtUJYrCMEy"}},{"cell_type":"code","source":["import numpy as np\n","import math\n","\n","B = np.array([[1,3,4],[2,-1,2],[4,-1,0]])\n","print(A[0])\n","\n","def F_norm(A):\n","  sum = 0\n","  for row in A:\n","    for element in row:\n","      sum += element**2\n","  return math.sqrt(sum)\n","\n","print(F_norm(B))\n","print(np.linalg.norm(B))"],"metadata":{"id":"lkjVpzAvuOzo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675731650051,"user_tz":480,"elapsed":130,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"9d049458-f67f-4b19-9f53-65eef6be656b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 3 4]\n","7.211102550927978\n","7.211102550927978\n"]}]},{"cell_type":"markdown","source":["### III. Matrix Spaces\n","\n","A <u>matrix equation</u> $A\\vec{x} = \\vec{b}$ has three possible outcomes for its solution vector $\\vec{x}$:\n","\n","1. There is a unique solution.\n","2. There are infinitely many solutions.\n","3. There are no solutions.\n","\n","**Question**. What does it mean for the matrix equation $Ax=b$ to be \"well-defined?\"\n","\n","**Question**. What does it mean to \"find a solution\" to $Ax=b$? (Think in terms of linear combinations of the columns of $A$.)\n","\n","To do advanced analysis (such as finding eigenvectors or supervised learning models) we need to describe these 3 cases in terms of vector subspaces (the textbook calls them matrix spaces).\n","\n","Recall that we can build new vectors from old vectors by the vector equation:\n","\n","\\begin{align} \\mathbb{w} = \\lambda_1\\mathbb{v_1} + \\lambda_2\\mathbb{v_2} + ... + \\lambda_n\\mathbb{v_p}. \\end{align}\n","These are linear combinations of vectors giving us a (possibly) new vector $w$.\n","\n","Take $w = \\vec{0}$. If there does not exist a set of weights that satisfy the above equation then we say that the set of vectors $V$ is a *linearly independent* set.\n","\n","Also, recall that a *subspace* of $\\mathbb{R}^n$ is a subset $V$ such that:\n","1. $\\vec{0} \\in V$\n","2. $\\vec{u}, \\vec{v} \\in V ⇒ \\vec{u} + \\vec{v} \\in V$\n","3. $\\vec{v} \\in V ⇒ k\\vec{v} \\in V$.\n","\n","\"Matrix Spaces\" are special vector subspaces that are generated by matrices (in the context of matrix equations $A\\vec{x} = \\vec{b}$)."],"metadata":{"id":"pFczEjBSjnBq"}},{"cell_type":"markdown","source":["#### Column Space.\n","\n","If we consider the columns of a matrix to be individual vectors $\\vec{a_1}$, $\\vec{a_2}$, ..., $\\vec{a_m}$, then we can define the *column space* of a matrix $A$ as\n","\n","$\\begin{align}\n","C(A) & = \\{\\lambda_1\\vec{a_1} + \\lambda_2\\vec{a_2} + ... + \\lambda_m\\vec{a_m} : \\lambda_i \\in \\mathbb{R}\\}\n","\\end{align}$.\n","\n","\"For a given vector $\\vec{v}$, do there exist weights $\\lambda_1, ..., \\lambda_m$ such that I can get $\\vec{v}$ via linear combinations of the columns of matrix $A$?\" If yes, then $\\vec{v}$ is in the column space of $A$."],"metadata":{"id":"3O8oFrAVj0Oe"}},{"cell_type":"markdown","source":["**Question**. If $A$ is $n \\times m$ then the vectors in $C(A)$ are in $\\mathbb{R}^?$."],"metadata":{"id":"-fW8GOLdj_MC"}},{"cell_type":"markdown","source":["**Examples**. Describe the column space for each of the following matrices.\n","\n","\n","1.   [[1, 2], [2, 4]]\n","2.   [[1, 2], [3, -2]]\n","3.   [[1, 0, 2], [0, 1, 5], [1, 1, 7]]\n","4.   [[1, 0, 2], [0, 1, 5], [0, 0, 1]]"],"metadata":{"id":"m-lkz6SBkCWO"}},{"cell_type":"markdown","source":["**Question**. How can we think of the existence of a solution to the matrix equation $Ax=b$ in terms of $C(A)$? If a solution exists then $b \\in$ ____.\n","\n","**Question**. How can we think of the uniqueness of a solution to $Ax=b$ in terms of $C(A)$?"],"metadata":{"id":"Z3PmxMuokIA-"}}]}
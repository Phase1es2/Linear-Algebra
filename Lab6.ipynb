{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oCeu7WMeovJ33qNN1X0gooXxvPAvEUHx","timestamp":1678320106316}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Lab 6: Classification Models\n","\n","The purpose of this lab is to utilize the computing power of the scikit-learn environment to build linear models that predict categorical variable values.\n","\n"],"metadata":{"id":"qj0b7z5VN5Ac"}},{"cell_type":"markdown","source":["### I. The Titanic Data Set\n","\n","If you are unfamiliar with the Titanic disaster or need a refresher, I recommend reading https://en.wikipedia.org/wiki/Sinking_of_the_Titanic before starting this lab.\n","\n","For this lab we will analyze the a well-known data set that contains data on the passengers of the Titanic. You can read about the data set (and the famous Kaggle machine learning competition that utilizes it) here: https://www.kaggle.com/competitions/titanic/data.\n","\n","The data set itself is split into two sub-data sets: ```titanic_train``` and ```titanic_test```. We will build our models by fitting them to ```titanic_train```. It is common practice to test a model's performance on the data that it hasn't seen (```titanic_test```) but we won't do so in this lab.\n","\n"],"metadata":{"id":"dWkW6WAqPRmE"}},{"cell_type":"markdown","source":["#### Preprocessing."],"metadata":{"id":"WNSyCGkl-Do3"}},{"cell_type":"markdown","source":["Before uploading ```titanic_train```, open and view the data in excel. You will notice that missing data is a real problem with this data set, which means that we will have to do more preprocessing than usual. There are two people for which the ```Embarked``` variable is missing. Do an internet search to determine what these values should be, then enter them into the raw data set in excel, then save the modified ```titanic_train.csv``` file on your local machine."],"metadata":{"id":"dFM67LNIRcR2"}},{"cell_type":"code","source":["# Import the titanic_train dataset\n","from google.colab import files\n","\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"id":"lW55tDvbR3Ya","outputId":"9f03ad78-376e-4b58-a8a3-6f8ca15e69ce","executionInfo":{"status":"ok","timestamp":1678424308542,"user_tz":480,"elapsed":7947,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-09d10de3-ced1-438a-9dd3-99a30cfd8bff\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-09d10de3-ced1-438a-9dd3-99a30cfd8bff\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving titanic_train.csv to titanic_train.csv\n"]}]},{"cell_type":"code","source":["# View dataset\n","import pandas as pd\n","\n","titanic_train = pd.read_csv(\"titanic_train.csv\")\n","titanic_train.head()"],"metadata":{"id":"VdLSxiMhcar2","colab":{"base_uri":"https://localhost:8080/","height":548},"executionInfo":{"status":"ok","timestamp":1678434300321,"user_tz":480,"elapsed":141,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"754cd2b2-bded-4f73-911a-d11b27ef0fef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Name  Survived  Pclass  \\\n","0                            Braund, Mr. Owen Harris         0       3   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...         1       1   \n","2                             Heikkinen, Miss. Laina         1       3   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)         1       1   \n","4                           Allen, Mr. William Henry         0       3   \n","\n","      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n","0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n","1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n","2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n","3  female  35.0      1      0            113803  53.1000  C123        S  \n","4    male  35.0      0      0            373450   8.0500   NaN        S  "],"text/html":["\n","  <div id=\"df-025f761f-d1ba-4a32-918a-7fe2abf2dc97\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-025f761f-d1ba-4a32-918a-7fe2abf2dc97')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-025f761f-d1ba-4a32-918a-7fe2abf2dc97 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-025f761f-d1ba-4a32-918a-7fe2abf2dc97');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":216}]},{"cell_type":"markdown","source":["**Exercise 1**. How many different ports did the Titanic embark from?"],"metadata":{"id":"KHGYgxzKT0Ry"}},{"cell_type":"code","source":["#S,Q,C\n","#3"],"metadata":{"id":"GZiqD3dArW3d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will use the ```Pclass```, ```Sex```, ```Age```, ```SibSp```, ```Parch```, ```Fare```, and ```Embarked``` variables to predict ```Survived```. In order to make the categorical variables ```Pclass```, ```Sex```, and ```Embarked``` viable model inputs we need to represent them using numbers. I have included a block of code that will do this for you below. Run it and read this blog post: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/."],"metadata":{"id":"eRSbDQUMSPU2"}},{"cell_type":"code","source":["# Preprocess that data set: Do not change this code!\n","\n","from sklearn.preprocessing import OneHotEncoder\n","\n","df = titanic_train.drop([\"Name\",\"Ticket\", \"Cabin\"], axis = 1)\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","encoder_df = pd.DataFrame(encoder.fit_transform(df[['Pclass', 'Embarked']]).toarray())\n","final_df = df.join(encoder_df)\n","final_df = final_df.drop([\"Pclass\", \"Embarked\"], axis = 1)\n","final_df['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\n","final_df.columns = [\"Survived\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass1\", \"Pclass2\", \"Pclass3\", \"EmbarkC\", \"EmbarkQ\", \"EmbarkS\"]\n","titanic_train = final_df # titanic_train is still a pandas dataframe\n","titanic_train.head()"],"metadata":{"id":"dA0x321Qdf9T","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"ok","timestamp":1678434302541,"user_tz":480,"elapsed":162,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"839c4078-1f50-4056-ac78-ce684985f9d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Survived  Sex   Age  SibSp  Parch     Fare  Pclass1  Pclass2  Pclass3  \\\n","0         0    0  22.0      1      0   7.2500      0.0      0.0      1.0   \n","1         1    1  38.0      1      0  71.2833      1.0      0.0      0.0   \n","2         1    1  26.0      0      0   7.9250      0.0      0.0      1.0   \n","3         1    1  35.0      1      0  53.1000      1.0      0.0      0.0   \n","4         0    0  35.0      0      0   8.0500      0.0      0.0      1.0   \n","\n","   EmbarkC  EmbarkQ  EmbarkS  \n","0      0.0      0.0      1.0  \n","1      1.0      0.0      0.0  \n","2      0.0      0.0      1.0  \n","3      0.0      0.0      1.0  \n","4      0.0      0.0      1.0  "],"text/html":["\n","  <div id=\"df-ff6a9968-2cf7-4fe5-b654-fdf2dbc91056\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Pclass1</th>\n","      <th>Pclass2</th>\n","      <th>Pclass3</th>\n","      <th>EmbarkC</th>\n","      <th>EmbarkQ</th>\n","      <th>EmbarkS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff6a9968-2cf7-4fe5-b654-fdf2dbc91056')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ff6a9968-2cf7-4fe5-b654-fdf2dbc91056 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ff6a9968-2cf7-4fe5-b654-fdf2dbc91056');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":217}]},{"cell_type":"markdown","source":["**Exercise 2**. What is the type of encoding that was used to express the ```Pclass``` and ```Embark``` variables as numbers? What is the logic for doing this?"],"metadata":{"id":"Dt98lE-QUuxm"}},{"cell_type":"code","source":["# Construct the design matrix X and y vector here.\n","from sklearn import preprocessing\n","#X = titanic_train.to_numpy()[:,1:11]\n","#y = titanic_train.to_numpy()[:,0]\n","X = titanic_train.to_numpy()[:,[1,2,3,4,5,6,7,8,9,10,11]]\n","y = titanic_train.to_numpy()[:,0]\n","\n","rows, columns = X.shape\n","\n","print(\"The number of rows in X is:\", rows)\n","print(\"The number of columns in X is:\", columns)\n","print(X)\n","print()\n","print(y)\n","\n","\n","#The type of encoding used in this code is One-hot encoding.\n","\n","#One-hot encoding is a process of converting categorical variables into a numerical representation. In this case, the categorical variables 'Pclass' and 'Embarked' are converted into multiple binary columns (also known as dummy variables) representing each unique category."],"metadata":{"id":"E7gLD5cTQJl8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434306081,"user_tz":480,"elapsed":2,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"2b0bdf62-384f-4316-ddfd-bcfc5e05f503"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of rows in X is: 891\n","The number of columns in X is: 11\n","[[ 0. 22.  1. ...  0.  0.  1.]\n"," [ 1. 38.  1. ...  1.  0.  0.]\n"," [ 1. 26.  0. ...  0.  0.  1.]\n"," ...\n"," [ 1. nan  1. ...  0.  0.  1.]\n"," [ 0. 26.  0. ...  1.  0.  0.]\n"," [ 0. 32.  0. ...  0.  1.  0.]]\n","\n","[0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n"," 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n"," 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.\n"," 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n"," 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n"," 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0.\n"," 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n"," 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n"," 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n"," 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n"," 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1.\n"," 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n"," 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1.\n"," 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n"," 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n"," 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n"," 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n"," 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n"," 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1.\n"," 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n"," 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n"," 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n"," 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n"," 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n"," 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 1. 0.]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"sVZMMS9facGC"}},{"cell_type":"markdown","source":["We dropped the ```Ticket``` and ```Cabin``` variables because there were so many missing values. We are using the ```Age``` variable in our design matrix but it is also missing values. In class we have:\n","\n","1. Replaced missing values with column means.\n","\n","2. Dropped rows with missing values.\n","\n","A third option is to use regression to estimate the missing ```age``` values from the other variables. For this data set we will use a method called K-Nearest-Neighbors (KNN), which estimates the missing value based on the average of the ```age``` variable in the *k* closest vectors. This can be seen as a more accurate and improved (though more computationally costly) version of #1 above.  "],"metadata":{"id":"EqwdhfKJViWU"}},{"cell_type":"code","source":["# Fill in missing age values using KNN- just run this code.\n","\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors = 5)\n","X = imputer.fit_transform(X)\n","print(X)"],"metadata":{"id":"cBRey_AHjPqD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434310818,"user_tz":480,"elapsed":305,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"35de91b3-3481-4b2a-b085-f89f630a8757"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.  22.   1.  ...  0.   0.   1. ]\n"," [ 1.  38.   1.  ...  1.   0.   0. ]\n"," [ 1.  26.   0.  ...  0.   0.   1. ]\n"," ...\n"," [ 1.  16.8  1.  ...  0.   0.   1. ]\n"," [ 0.  26.   0.  ...  1.   0.   0. ]\n"," [ 0.  32.   0.  ...  0.   1.   0. ]]\n"]}]},{"cell_type":"markdown","source":["As we saw in class, standardizing the design matrix by changing it to z-scores will improve the logistic regression algorithm's performance. Change ```X``` into ```X_std``` as we did in class."],"metadata":{"id":"NXqjkXlxYqYs"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","\n","scaler = preprocessing.StandardScaler() #construct the scalar object\n","X_std = scaler.fit_transform(X) #deploy and calculate\n","rows, columns = X_std.shape\n","print(rows)\n","print(columns)\n","\n","print(X_std)\n"],"metadata":{"id":"iTFhblrgU6iH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434312824,"user_tz":480,"elapsed":147,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"cdff11ec-e712-4302-db98-62ed4145c2a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["891\n","11\n","[[-0.73769513 -0.59541179  0.43279337 ... -0.4838099  -0.30974338\n","   0.61930636]\n"," [ 1.35557354  0.5833991   0.43279337 ...  2.06692751 -0.30974338\n","  -1.61470971]\n"," [ 1.35557354 -0.30070907 -0.4745452  ... -0.4838099  -0.30974338\n","   0.61930636]\n"," ...\n"," [ 1.35557354 -0.97852532  0.43279337 ... -0.4838099  -0.30974338\n","   0.61930636]\n"," [-0.73769513 -0.30070907 -0.4745452  ...  2.06692751 -0.30974338\n","  -1.61470971]\n"," [-0.73769513  0.14134501 -0.4745452  ... -0.4838099   3.22847904\n","  -1.61470971]]\n"]}]},{"cell_type":"markdown","source":["### II. The Logistic Regression Model\n","\n","Build a logistic regression model called ```titanic_model``` in python using ```sklearn```. The full model will have the form:\n","\n","\\begin{align} \\hat{p(\\vec{x}}) = \\frac{e^{\\hat{\\beta_0} + \\hat{\\beta_1}Sex + \\hat{\\beta_2}Age + \\hat{\\beta_3}Sibsp + \\hat{\\beta_4}Parch + \\hat{\\beta_5}Fare + \\hat{\\beta_6}Pclass1 + \\hat{\\beta_7}Pclass2 + \\hat{\\beta_8}Pclass3 + \\hat{\\beta_9}EmbarkedC + \\hat{\\beta_{10}}EmbarkedQ + \\hat{\\beta_{11}}EmbarkedS}}{1 + e^{\\hat{\\beta_0} + \\hat{\\beta_1}Sex + \\hat{\\beta_2}Age + \\hat{\\beta_3}Sibsp + \\hat{\\beta_4}Parch + \\hat{\\beta_5}Fare + \\hat{\\beta_6}Pclass1 + \\hat{\\beta_7}Pclass2 + \\hat{\\beta_8}Pclass3 + \\hat{\\beta_9}EmbarkedC + \\hat{\\beta_{10}}EmbarkedQ + \\hat{\\beta_{11}}EmbarkedS}} \\end{align}\n"],"metadata":{"id":"bL2949HcZJaK"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","titanic_model = LogisticRegression().fit(X_std, y)\n","\n","print(titanic_model.coef_)\n","print()\n","print(titanic_model.intercept_)\n"],"metadata":{"id":"TDTO_OC5eQgp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434315293,"user_tz":480,"elapsed":1,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"64bda873-6743-40a2-c858-8edd7a70952d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.2547952  -0.52444834 -0.34613562 -0.07558441  0.09700901  0.51818866\n","   0.08302305 -0.5140426   0.07182477  0.05503385 -0.0976545 ]]\n","\n","[-0.65349996]\n"]}]},{"cell_type":"markdown","source":["**Exercise 3**. State $\\hat{\\beta_1}$. What does its sign tell you about the model's prediction of a female suriving relative to a male?"],"metadata":{"id":"WZVfAxmcbUBJ"}},{"cell_type":"code","source":["import numpy as np\n","\n","\n","p_female = 1 / (1 + np.exp(- (titanic_model.intercept_ + 1.2547952 * 1)))\n","print(p_female)\n","print()\n","p_male = 1 / (1 + np.exp(- (titanic_model.intercept_)))\n","print(p_male)\n","\n","#this means that female has more suriving rate than male."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lbs-iCuP76v-","executionInfo":{"status":"ok","timestamp":1678434317280,"user_tz":480,"elapsed":1,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"91399e5d-eeb9-4738-8666-55b1da3f8edd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.64595258]\n","\n","[0.34220126]\n"]}]},{"cell_type":"markdown","source":["**Exercise 4**. State $\\hat{\\beta_2}$. The sign tells you that a passenger had a better chance of survival the ____ they were. Given what you know about who got priority getting into the lifeboats, why does this make sense?"],"metadata":{"id":"MCtBYSqng4Bf"}},{"cell_type":"code","source":["#The negative sign of b_hat2 indicates that the model predicts a decrease in the log odds of survival as the age of the passenger increases. This means that, according to the model, younger passengers have a better chance of survival compared to older passengers. This is consistent with what we know about who got priority getting into the lifeboats during the Titanic disaster, where women and children were given priority.\n"],"metadata":{"id":"fiq8LQh02PeQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise 5**. Which value of the original ```Embarked``` variable gave a passenger the worse chances of survival, accouring to the models betas? Explain your answer."],"metadata":{"id":"dpG5a2-NjAvx"}},{"cell_type":"code","source":[" #-5.07298157e-04  3.38187023e-02  1.13573897e-01\n","p_C = 1 / (1 + np.exp(- (titanic_model.intercept_ + 0.07182477 * 1)))\n","p_Q = 1 / (1 + np.exp(- (titanic_model.intercept_ + 0.05503385 * 1)))\n","p_S = 1 / (1 + np.exp(- (titanic_model.intercept_ + -0.0976545 * 1)))\n","print(\"p_C: \", p_C)\n","print(\"p_Q: \", p_Q)\n","print(\"p_S: \", p_S)\n","#EmbarkC will have less survival rate, since the titanic_model.coef_ for EmbarkC， EmbarkQ， EmbarkS are -5.07298157e-04,  3.38187023e-02,  1.13573897e-01\n","#the EmbarkC has the lowest value, and by using p = 1 / (1 + np.exp(- (titanic_model.intercept_ + b_hat * 1)))\n","#we can predict the probability of survial for a passenger in different embark\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-wgFcDV2Sel","executionInfo":{"status":"ok","timestamp":1678434322100,"user_tz":480,"elapsed":2,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"3fec95b3-9a3a-4e21-97ec-575d18b2b44c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["p_C:  [0.35854722]\n","p_Q:  [0.3546947]\n","p_S:  [0.3205698]\n"]}]},{"cell_type":"markdown","source":["**Exercise 6**. Find the model's accuracy.\n","\n"],"metadata":{"id":"DK9ClS7HlSKg"}},{"cell_type":"code","source":["from sklearn import metrics\n","\n","y_hat = titanic_model.predict(X_std)\n","confusion_matrix = metrics.confusion_matrix(y,y_hat, labels = titanic_model.classes_)\n","\n","print(confusion_matrix)"],"metadata":{"id":"g41GqvmoCosY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434325206,"user_tz":480,"elapsed":461,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"25bd7ef4-6a1f-4508-e4ce-a387c6fdc0c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[481  68]\n"," [100 242]]\n"]}]},{"cell_type":"code","source":["tn, fp, fn, tp = confusion_matrix.ravel()\n","accuracy = (tp + tn)/X.shape[0]\n","print(accuracy)\n","#0.8114"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpS7OAmF_LCI","executionInfo":{"status":"ok","timestamp":1678434328078,"user_tz":480,"elapsed":257,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"a4e72a9d-06d6-44aa-e935-22470d385d54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8114478114478114\n"]}]},{"cell_type":"markdown","source":["**Exercise 7**. Find the model's F1-score."],"metadata":{"id":"H7X8DJmflYJ_"}},{"cell_type":"code","source":["precision = tp/(tp+fp)\n","recall = tp/(tp + fn)\n","\n","f_1 = 2*precision*recall/(precision + recall)\n","print(f_1)\n","\n","#0.7423\n"],"metadata":{"id":"GAA6Ns1xVOxw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434329029,"user_tz":480,"elapsed":2,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"91facdfb-880b-4272-b0a3-c3cb4370ec19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7423312883435583\n"]}]},{"cell_type":"markdown","source":["**Exercise 8**. A \"null\" model that predicts \"did not survive\" for any value of inputs would achieve an accuracy of ___.  "],"metadata":{"id":"an2XQAa-6Cav"}},{"cell_type":"code","source":["num_survive = sum(y)\n","print(num_survive)\n","\n","accuracy_null = (X.shape[0]-num_survive)/X.shape[0]\n","print(accuracy_null)\n","#0.616\n"],"metadata":{"id":"lX9KJak86TK-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434331055,"user_tz":480,"elapsed":661,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"6f0e8155-e888-4c62-f042-b2750585ef74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["342.0\n","0.6161616161616161\n"]}]},{"cell_type":"markdown","source":["**Exercise 9**. Jack Dawson, a 20 year old man in Southampton, wins a 3rd class ticket (valued at $8) in a poker game. He’s traveling without relatives. What does ```titanic_model``` estimate for his likelihood of surival? (Hint: See revised class notes for lecture 9w. I messed this up in class- I forgot to standardize ```mom```!)"],"metadata":{"id":"mxqofnespfIx"}},{"cell_type":"code","source":["#12%\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","jack = np.array([[0,20,0,0,8,0,0,1,0,0,1]])\n","jack_std = scaler.transform(jack)\n","print(titanic_model.predict_proba(jack_std))\n","\n"],"metadata":{"id":"S4l9UvV4pbhX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434332553,"user_tz":480,"elapsed":2,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"0af5a07e-b968-45a8-c7a8-ef93bc397571"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.87528967 0.12471033]]\n"]}]},{"cell_type":"markdown","source":["[[-0.73769513 -0.74276315 -0.4745452  -0.47367361 -0.48734416 -0.56568542\n","  -0.51015154  0.90258736 -0.4838099  -0.30974338  0.61930636]]\n","[[0.87528967 0.12471033]]"],"metadata":{"id":"3VFbXogaawP6"}},{"cell_type":"markdown","source":["### III. A Neural Network Model\n","\n","A more computationally expensive way to do classification is neural networks and deep learning. Read about the multi-layer perceptron here: https://scikit-learn.org/stable/modules/neural_networks_supervised.html.\n"],"metadata":{"id":"eMN2zILG8iqt"}},{"cell_type":"markdown","source":["**Exercise 10**. Build and fit an ```MLPClassifier``` called ```titanic_nn```. Use the \"adam\" solver, with an alpha of 1e-4, hidden layer sizes of (36, 8), maximum iterations of 10,0000, and a random state of 1 (for reproducability). What F1-score does this model achieve?  "],"metadata":{"id":"0n1slrtZnJ1-"}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import f1_score\n","# Create the MLPClassifier object\n","titanic_nn = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(36, 8), max_iter=10000, random_state=1)\n","titanic_nn.fit(X_std, y)\n","\n","y_hat = titanic_nn.predict(X_std)\n","print(\"y_hat\", y_hat)\n","\n","confusion_matrix = metrics.confusion_matrix(y,y_hat, labels = titanic_nn.classes_)\n","\n","print(confusion_matrix)\n","\n","\n","tn, fp, fn, tp = confusion_matrix.ravel()\n","accuracy = (tp + tn)/X.shape[0]\n","print(\"accuracy: \", accuracy)\n","\n","\n","precision = tp/(tp+fp)\n","recall = tp/(tp + fn)\n","\n","f_1 = 2*precision*recall/(precision + recall)\n","print(\"f_1: \", f_1)\n","\n","\n","#0.8432"],"metadata":{"id":"q75jgT6e8kyJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678434722817,"user_tz":480,"elapsed":4687,"user":{"displayName":"Hao Yang","userId":"14112675994208019369"}},"outputId":"93820816-c63d-4b38-c196-407987286b9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["y_hat [0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1.\n"," 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n"," 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n"," 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n"," 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n"," 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n"," 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n"," 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n"," 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.\n"," 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n"," 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n"," 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0.\n"," 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.\n"," 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n"," 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n"," 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n"," 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n"," 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n"," 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n"," 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n"," 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n"," 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n"," 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1.\n"," 0. 1. 0.]\n","[[518  31]\n"," [ 67 275]]\n","accuracy:  0.8900112233445566\n","f_1:  0.8487654320987654\n"]}]},{"cell_type":"markdown","source":["### IV. Course Evaluations\n","\n","**Exercise 11**. You should have recieved a link for the course evaluation form. Please complete the form for 1 point of extra credit on this assignment."],"metadata":{"id":"Ku0Jal-7oJ22"}},{"cell_type":"markdown","source":["o determine whether this was a good portfolio for the investor, we need to calculate the expected return and the risk of the portfolio.\n","The expected return for stock A is 10% and for stock B is -2%. Thus, the expected return on the portfolio is:\n","\n","Expected return = 0.3 x 10% + 0.7 x (-2%) = 2.8%\n","\n","The risk of the portfolio can be measured by calculating its standard deviation. The formula for calculating the standard deviation of a two-asset portfolio is:\n","\n","σp = sqrt(w1^2σ1^2 + w2^2σ2^2 + 2w1w2ρσ1σ2)\n","\n","Where w1 and w2 are the weights of stock A and stock B respectively, σ1 and σ2 are the standard deviations of stocks A and B respectively, ρ is the correlation coefficient between the returns of the two stocks.\n","\n","Using the above formula with the given values, we get:\n","\n","σp = sqrt((0.3^2x10^2 + 0.7^2x(-2)^2 + 2x0.3x0.7x0x10x(-2))\n","\n","σp=8.007%\n","\n","As the expected return of the portfolio is less than the average rate of return, but before taking the risk into account, the portfolio might appear to be a profitable one. However, after accounting for risk (as shown through the high standard deviation), the investor may be better off exploring other investment opportunities.\n","\n","Assuming that short-selling is not allowed, we can use the capital asset pricing model (CAPM) to find the optimal portfolio allocation. The CAPM formula is:\n","Expected return = Rf + β(Rm - Rf)\n","\n","where Rf is the risk-free rate, β is the beta of the stock, Rm is the market return.\n","\n","To derive the required inputs for this equation, first, we calculate the beta for each stock:\n","\n","βA = 0 (not given)\n","βB = -2%/10% = -0.2\n","\n","Next, based on the definition in question, the treasury bill rate can be used as the risk-free rate. This value has been mentioned as 6%.\n","\n","Finally, there is no mention of the market return in the problem statement. As such, we will assume that the expected market return over the past year was 8% (a typical value for an S&P index fund).\n","\n","Substituting the values in the CAPM formula, we obtain:\n","\n","Expected return of A = 6% + 0 × (8% - 6%) = 6%\n","Expected return of B = 6% + (-0.2) × (8% - 6%) = 5.6%\n","\n","Thus, a better portfolio choice would have been to allocate 100% of the investment to stock A.\n","\n","The Sharpe Ratio measures the excess return generated by an investment per unit of volatility. It is calculated as:\n","Sharpe Ratio = (Expected portfolio return – Risk-free rate) / Portfolio standard deviation\n","\n","Substituting the values from the previous answers, we obtain:\n","\n","SR = (2.8% – 6%) / 8.007% = -0.475\n","\n","A negative Sharpe Ratio suggests that the portfolio had a poor risk-return tradeoff and thus would not have been an ideal option for an investor.\n","\n"],"metadata":{"id":"Xjsng9EKad1M"}}]}